{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15afe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fe887b-d30f-4c00-acef-3c7a4902ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evallm.experiments.evaluate_tokenization_regexp_non_icl import (\n",
    "    table_of_results,\n",
    "    text_table,\n",
    "    latex_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83675297-dc07-4e4f-a42e-d1ccb9305e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table_of_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900ae33b-f76a-4e37-bbbe-f14e7e6a83a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models mistral-nemo-minitron-8B, mistral-nemo-base-12B, falcon-7b, deepseek-coder-33b-instruct have non-response rates over 98\\%\n"
     ]
    }
   ],
   "source": [
    "non_response_threshold = 0.98\n",
    "non_responses = table[table.non_response > non_response_threshold]\n",
    "print(\n",
    "    \"Models\",\n",
    "    \", \".join(non_responses.index),\n",
    "    f\"have non-response rates over {non_response_threshold:.0%}\".replace(\"%\", \"\\\\%\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14950e48-9b1d-4e35-9c53-88319aa89798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8B                       66%\n",
      "llama3-70B                      80% [Non-response: 26%]\n",
      "llama3.1-8B-Instruct            83%\n",
      "llama3.1-8B                     89%\n",
      "llama3.1-70B                    86% [Non-response: 36%]\n",
      "qwen-2.5-7B                     62%\n",
      "qwen-2.5-32B                   100%\n",
      "mistral-nemo-instruct-12B       99%\n",
      "gemma-7b                        67% [Non-response: 15%]\n",
      "starcoder2-15b                  62%\n",
      "codestral-22B                   95%\n",
      "qwen-2.5-coder-7B              100%\n",
      "qwen-2.5-coder-instruct-7B      56%\n",
      "qwen-2.5-coder-instruct-32B     96%\n",
      "gpt-3.5-instruct                67%\n",
      "gpt-3.5-chat                    82%\n",
      "gpt-4o-mini                    100%\n",
      "gpt-4o                         100%\n",
      "claude-3.5                     100%\n",
      "o3-mini                        100%\n"
     ]
    }
   ],
   "source": [
    "text_table(table, non_response_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b219b3-750d-407e-843b-093caa93b33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l r r}\n",
      "\\toprule\n",
      "Model & Accuracy & Non-response \\\\\n",
      "\\midrule\n",
      "llama3-8B & 66\\% &  \\\\\n",
      "llama3-70B & 80\\% & 26\\% \\\\\n",
      "llama3.1-8B-Instruct & 83\\% &  \\\\\n",
      "llama3.1-8B & 89\\% &  \\\\\n",
      "llama3.1-70B & 86\\% & 36\\% \\\\\n",
      "qwen-2.5-7B & 62\\% &  \\\\\n",
      "qwen-2.5-32B & 100\\% &  \\\\\n",
      "mistral-nemo-instruct-12B & 99\\% &  \\\\\n",
      "gemma-7b & 67\\% & 15\\% \\\\\n",
      "starcoder2-15b & 62\\% &  \\\\\n",
      "codestral-22B & 95\\% &  \\\\\n",
      "qwen-2.5-coder-7B & 100\\% &  \\\\\n",
      "qwen-2.5-coder-instruct-7B & 56\\% &  \\\\\n",
      "qwen-2.5-coder-instruct-32B & 96\\% &  \\\\\n",
      "gpt-3.5-instruct & 67\\% &  \\\\\n",
      "gpt-3.5-chat & 82\\% &  \\\\\n",
      "gpt-4o-mini & 100\\% &  \\\\\n",
      "gpt-4o & 100\\% &  \\\\\n",
      "claude-3.5 & 100\\% &  \\\\\n",
      "o3-mini & 100\\% &  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "latex_table(table, non_response_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e677c-f922-4d08-bb3d-d6ca74e32888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
