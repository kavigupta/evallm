{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69506b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d030aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from evallm.experiments.sequence_completion_summary import (\n",
    "    sequence_completion_results,\n",
    "    display_prompt as display_prompt_sc,\n",
    "    sequence_completion_null_results,\n",
    ")\n",
    "\n",
    "from evallm.experiments.transducer_summary import (\n",
    "    transducer_results,\n",
    "    transducer_null_results,\n",
    ")\n",
    "from evallm.experiments.main_tables import (\n",
    "    best_prompt,\n",
    "    multi_prompts,\n",
    "    main_table_of_results,\n",
    "    multi_prompt_table_of_results,\n",
    "    plot_transducer_vs_sequence_completion,\n",
    "    best_prompt,\n",
    "    all_p_values,\n",
    ")\n",
    "from evallm.experiments.main_tables import plot_significance\n",
    "\n",
    "from evallm.experiments.transducer_plotting import produce_table\n",
    "from evallm.experiments.models_display import model_by_display_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b362970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_t = transducer_null_results()\n",
    "null_sc = sequence_completion_null_results()\n",
    "results_t = transducer_results()\n",
    "results_sc = sequence_completion_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d2cd9",
   "metadata": {},
   "source": [
    "### Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd47e56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\\renewcommand{\\arraystretch}{1.25}\\begin{tabular}{l|ccc|ccccc}\n",
      "\\hline\n",
      "\\bf Model & \\bf Size & \\bf IT? & \\bf Code? & \\bf Sequence Completion & \\bf SR & \\bf Transducer & \\bf TR\\\\\n",
      "\\hline\n",
      "\\multicolumn{8}{c}{ \\bf Baselines} \\\\\n",
      "\\hline\n",
      "\\textsc{BruteForce} & -- &  &  & \\cellcolor{lightgray} 100.0 (99.9--100.0) & 1 & \\cellcolor{lightgray} 96.4 (96.2--96.7) & 1 \\\\\n",
      "\\hline\n",
      "6-\\textsc{Gram} & -- &  &  & \\bf 91.7 (91.0--92.4) & 2 & \\bf 93.5 (93.1--93.9) & 2 \\\\\n",
      "\\hline\n",
      "5-\\textsc{Gram} & -- &  &  & 91.2 (90.4--91.9) & 3 & 93.4 (93.0--93.7) & 3 \\\\\n",
      "\\hline\n",
      "4-\\textsc{Gram} & -- &  &  & 89.6 (88.7--90.4) & 4 & 91.1 (90.6--91.6) & 5 \\\\\n",
      "\\hline\n",
      "3-\\textsc{Gram} & -- &  &  & 87.0 (86.1--87.8) & 5 & 87.0 (86.4--87.6) & 21 \\\\\n",
      "\\hline\n",
      "2-\\textsc{Gram} & -- &  &  & 83.3 (82.2--84.2) & 8 & 74.5 (73.6--75.3) & 29 \\\\\n",
      "\\hline\n",
      "\\textsc{Common-Suffix} & -- &  &  & 84.7 (83.6--85.6) & 6 & -- & -- \\\\\n",
      "\\hline\n",
      "\\textsc{Random}$_S$/\\textsc{Null}$_T$ & -- &  &  & 53.3 (51.7--54.7) & 31 & 68.9 (68.2--69.6) & 30 \\\\\n",
      "\\hline\n",
      "\\multicolumn{8}{c}{ \\bf Open Weight Completion} \\\\\n",
      "\\hline\n",
      "llama3-8B & 8.0B &  &  & 73.8 (72.4--75.1) & 21 & 87.5 (86.9--88.0) & 19 \\\\\n",
      "\\hline\n",
      "llama3-70B & 70.6B &  &  & 71.4 (70.0--72.7) & 28 & 87.7 (87.2--88.3) & 16 \\\\\n",
      "\\hline\n",
      "llama3.1-8B-Instruct & 8.0B & \\checkmark &  & 75.3 (74.0--76.6) & 18 & 85.9 (85.3--86.5) & 23 \\\\\n",
      "\\hline\n",
      "llama3.1-8B & 8.0B & \\checkmark &  & 75.2 (73.8--76.3) & 19 & 88.0 (87.5--88.6) & 11 \\\\\n",
      "\\hline\n",
      "llama3.1-70B & 70.0B & \\checkmark &  & 71.8 (70.4--73.1) & 27 & 87.7 (87.2--88.2) & 18 \\\\\n",
      "\\hline\n",
      "qwen-2.5-7B & 7.6B &  &  & 73.5 (72.1--74.8) & 23 & \\bf 88.7 (88.2--89.2) & 6 \\\\\n",
      "\\hline\n",
      "qwen-2.5-32B & 32.5B &  &  & 76.8 (75.5--78.0) & 15 & 88.3 (87.8--88.8) & 8 \\\\\n",
      "\\hline\n",
      "mistral-nemo-minitron-8B & 8.4B &  &  & \\bf 78.7 (77.5--79.8) & 13 & 88.6 (88.0--89.1) & 7 \\\\\n",
      "\\hline\n",
      "mistral-nemo-base-12B & 12.2B &  &  & 75.5 (74.3--76.6) & 17 & 87.9 (87.4--88.4) & 14 \\\\\n",
      "\\hline\n",
      "mistral-nemo-instruct-12B & 12.2B & \\checkmark &  & 72.2 (70.9--73.4) & 26 & 88.0 (87.5--88.5) & 12 \\\\\n",
      "\\hline\n",
      "gemma-7b & 8.5B &  &  & 72.6 (71.3--73.7) & 24 & 82.1 (81.4--82.7) & 27 \\\\\n",
      "\\hline\n",
      "falcon-7b & 7.2B &  &  & 69.0 (67.6--70.2) & 29 & 84.9 (84.3--85.5) & 25 \\\\\n",
      "\\hline\n",
      "\\multicolumn{8}{c}{ \\bf Open Weight Code} \\\\\n",
      "\\hline\n",
      "starcoder2-15b & 16.0B &  & \\checkmark & 73.5 (72.0--74.7) & 22 & 87.7 (85.8--89.5) & 17 \\\\\n",
      "\\hline\n",
      "codestral-22B & 22.2B &  & \\checkmark & 78.0 (76.8--79.1) & 14 & 86.6 (86.0--87.1) & 22 \\\\\n",
      "\\hline\n",
      "deepseek-coder-33b-instruct & 33.3B & \\checkmark & \\checkmark & 76.7 (75.3--77.8) & 16 & 85.6 (85.0--86.2) & 24 \\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-7B & 7.6B &  & \\checkmark & \\bf 79.5 (78.4--80.5) & 10 & 88.2 (87.6--88.7) & 10 \\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-7B & 7.6B & \\checkmark & \\checkmark & 79.5 (78.3--80.5) & 11 & \\bf 88.3 (87.8--88.8) & 9 \\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-32B & 32.8B & \\checkmark & \\checkmark & 79.2 (78.0--80.3) & 12 & 87.9 (87.4--88.4) & 13 \\\\\n",
      "\\hline\n",
      "\\multicolumn{8}{c}{ \\bf Proprietary} \\\\\n",
      "\\hline\n",
      "gpt-3.5-instruct & ? & \\checkmark &  & 67.3 (63.1--71.5) & 30 & 87.8 (85.9--89.6) & 15 \\\\\n",
      "\\hline\n",
      "gpt-3.5-chat & ? & \\checkmark &  & N/A & -- & 66.8 (63.4--69.8) & 31 \\\\\n",
      "\\hline\n",
      "gpt-4o-mini & ? & \\checkmark &  & 72.4 (68.1--76.3) & 25 & 79.8 (77.3--82.2) & 28 \\\\\n",
      "\\hline\n",
      "gpt-4o & ? & \\checkmark &  & 74.8 (69.3--80.4) & 20 & 83.7 (80.1--86.9) & 26 \\\\\n",
      "\\hline\n",
      "claude-3.5 & ? & \\checkmark &  & \\bf 84.0 (79.3--88.4) & 7 & 87.1 (83.9--90.2) & 20 \\\\\n",
      "\\hline\n",
      "o3-mini & ? & \\checkmark &  & 81.1 (76.0--85.8) & 9 & \\bf 92.4 (91.3--93.5) & 4 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_table_of_results(best_prompt(results_t), best_prompt(results_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8f402",
   "metadata": {},
   "source": [
    "### Comparison of Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1656a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\\renewcommand{\\arraystretch}{1.25}\\begin{tabular}{l|ccccc}\n",
      "\\hline\n",
      "\\bf Model & \\bf \\textsc{Basic} & \\bf \\textsc{Basic-COT} & \\bf \\textsc{More-Expl} & \\bf \\textsc{More-Expl-COT} & \\bf \\textsc{Red-Green} \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{l}{ \\bf Sequence Completion} \\\\\n",
      "\\hline\n",
      "gpt-4o-mini & \\bf 72.4 (68.1--76.3) & 60.0 (55.8--64.4) & 70.5 (66.4--74.6) & 58.0 (53.4--62.4) & 59.1 (54.9--63.2) \\\\\n",
      "\\hline\n",
      "gpt-4o & 72.1 (65.9--78.2) & \\bf 74.8 (69.3--80.4) & N/A & 67.4 (60.8--73.8) & 74.4 (69.9--78.6) \\\\\n",
      "\\hline\n",
      "claude-3.5 & N/A & 82.8 (77.5--87.5) & N/A & \\bf 84.0 (79.3--88.4) & 80.0 (74.9--85.2) \\\\\n",
      "\\hline\n",
      "o3-mini & N/A & \\bf 81.1 (76.0--85.8) & N/A & 58.2 (49.6--66.8) & 69.8 (64.4--75.0) \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{l}{ \\bf Transducer} \\\\\n",
      "\\hline\n",
      "gpt-4o-mini & \\bf 79.8 (77.3--82.2) & 66.5 (64.3--68.7) & 76.7 (74.2--79.3) & 65.2 (63.1--67.4) & 74.5 (72.0--77.0) \\\\\n",
      "\\hline\n",
      "gpt-4o & \\bf 83.7 (80.1--86.9) & 67.8 (62.4--73.2) & 82.6 (79.1--85.9) & 67.8 (63.1--72.3) & 82.6 (78.8--86.3) \\\\\n",
      "\\hline\n",
      "claude-3.5 & 86.9 (83.3--90.0) & 74.2 (70.0--78.3) & \\bf 87.1 (83.9--90.2) & 76.4 (72.9--79.9) & 82.9 (78.9--86.9) \\\\\n",
      "\\hline\n",
      "o3-mini & 72.8 (68.4--77.3) & 74.7 (70.7--78.8) & 74.7 (70.3--79.2) & 86.1 (83.9--88.4) & \\bf 92.4 (91.3--93.5) \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_prompt_table_of_results(multi_prompts(results_t), multi_prompts(results_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4497f3",
   "metadata": {},
   "source": [
    "### Commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d492467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "produce_table(\n",
    "    {k: v for k, v in results_sc.items() if k in model_by_display_key},\n",
    "    [display_prompt_sc(p) for p in [\"Basic\", \"Basic-Commas\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4), dpi=400, facecolor=\"white\", tight_layout=True)\n",
    "plot_transducer_vs_sequence_completion(results_sc, results_t)\n",
    "plt.savefig(\"../output/sequence_completion_vs_transducer.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a6c93",
   "metadata": {},
   "source": [
    "### Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c440d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(r\"{\\scriptsize\")\n",
    "multi_prompt_table_of_results(\n",
    "    multi_prompts(null_t, minimum_number_prompts=1),\n",
    "    multi_prompts(null_sc, minimum_number_prompts=1),\n",
    "    bold_best=False,\n",
    ")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c732a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evallm.experiments.main_tables import flat_pandas_table, reorderings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca54843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def flat(result):\n",
    "    return {(k1, k2): np.mean(v) for k1, k2v in result.items() for k2, v in k2v.items()}\n",
    "\n",
    "\n",
    "for k, v in flat(null_sc).items():\n",
    "    if v < 0.05:\n",
    "        continue\n",
    "    if \"Commas\" in k[1]:\n",
    "        continue\n",
    "    print(k, v)\n",
    "    # print(k, np.mean(v))\n",
    "\n",
    "all_vals = np.array(\n",
    "    [\n",
    "        np.mean(v)\n",
    "        for null in (null_t, null_sc)\n",
    "        for vs in null.values()\n",
    "        for prompt, v in vs.items()\n",
    "        if \"Commas\" not in prompt\n",
    "    ]\n",
    ")\n",
    "\n",
    "all_vals[all_vals < 0.5].max(), all_vals[all_vals >= 0.6].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_sc = flat_pandas_table(results_sc, null_sc)\n",
    "table_t = flat_pandas_table(results_t, null_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642dbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sequence just same model\")\n",
    "reorderings(table_sc, same_model=True)\n",
    "print()\n",
    "print(\"Transducer just same model\")\n",
    "reorderings(table_t, same_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sequence just best prompt\")\n",
    "reorderings(table_sc, only_best_prompt=True)\n",
    "print()\n",
    "print(\"Transducer just best prompt\")\n",
    "reorderings(table_t, only_best_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_t = best_prompt(results_t)\n",
    "ps_t = all_p_values(flat_t)\n",
    "flat_sc = {\n",
    "    k: v\n",
    "    for k, v in best_prompt(results_sc).items()\n",
    "    if not isinstance(v, float) or not np.isnan(v)\n",
    "}\n",
    "ps_sc = all_p_values(flat_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 6\n",
    "_, axs = plt.subplots(1, 2, figsize=(size * 2, size), dpi=400, tight_layout=True)\n",
    "plot_significance(axs[0], flat_sc, ps_sc)\n",
    "axs[0].set_title(\"Sequence Completion\")\n",
    "plot_significance(axs[1], flat_t, ps_t)\n",
    "axs[1].set_title(\"Transducer\")\n",
    "plt.savefig(\"../output/significance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d429879-b8ba-4324-905c-894fd1d0d58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
