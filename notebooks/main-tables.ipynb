{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69506b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d030aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from evallm.experiments.sequence_completion_summary import (\n",
    "    sequence_completion_results,\n",
    "    display_prompt as display_prompt_sc,\n",
    "    sequence_completion_null_results,\n",
    ")\n",
    "\n",
    "from evallm.experiments.transducer_summary import (\n",
    "    transducer_results,\n",
    "    transducer_null_results,\n",
    ")\n",
    "from evallm.experiments.main_tables import (\n",
    "    best_prompt,\n",
    "    multi_prompts,\n",
    "    main_table_of_results,\n",
    "    multi_prompt_table_of_results,\n",
    "    plot_transducer_vs_sequence_completion,\n",
    "    best_prompt,\n",
    "    all_p_values,\n",
    ")\n",
    "from evallm.experiments.main_tables import plot_significance\n",
    "\n",
    "from evallm.experiments.transducer_plotting import produce_table\n",
    "from evallm.experiments.models_display import model_by_display_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362970b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f839b3bfd7e64687a575de086312d1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_t = transducer_null_results()\n",
    "null_sc = sequence_completion_null_results()\n",
    "results_t = transducer_results()\n",
    "results_sc = sequence_completion_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d2cd9",
   "metadata": {},
   "source": [
    "### Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47e56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_table_of_results(best_prompt(results_t), best_prompt(results_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8f402",
   "metadata": {},
   "source": [
    "### Comparison of Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1656a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\\renewcommand{\\arraystretch}{1.25}\\begin{tabular}{l|ccccc}\n",
      "\\hline\n",
      "\\bf Model & \\bf \\textsc{Basic} & \\bf \\textsc{Basic-COT} & \\bf \\textsc{More-Expl} & \\bf \\textsc{More-Expl-COT} & \\bf \\textsc{Red-Green} \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{l}{ \\bf Sequence Completion} \\\\\n",
      "\\hline\n",
      "gpt-4o-mini & \\bf 72.4 (68.1--76.3) & -- & 70.5 (66.4--74.6) & 58.0 (53.4--62.4) & 59.1 (54.9--63.2) \\\\\n",
      "\\hline\n",
      "gpt-4o & 72.1 (65.9--78.2) & -- & N/A & 67.4 (60.8--73.8) & \\bf 74.4 (69.9--78.6) \\\\\n",
      "\\hline\n",
      "claude-3.5 & N/A & -- & N/A & \\bf 84.0 (79.3--88.4) & 80.0 (74.9--85.2) \\\\\n",
      "\\hline\n",
      "o3-mini & N/A & -- & N/A & 58.2 (49.6--66.8) & \\bf 69.8 (64.4--75.0) \\\\\n",
      "\\hline\n",
      "gpt-5 & 71.0 (58.3--82.7) & -- & -- & -- & \\bf 86.0 (76.7--94.6) \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{l}{ \\bf Transducer} \\\\\n",
      "\\hline\n",
      "gpt-4o-mini & \\bf 79.8 (77.3--82.2) & -- & 76.7 (74.2--79.3) & 65.2 (63.1--67.4) & 74.5 (72.0--77.0) \\\\\n",
      "\\hline\n",
      "gpt-4o & \\bf 83.7 (80.1--86.9) & -- & 82.6 (79.1--85.9) & 67.8 (63.1--72.3) & 82.6 (78.8--86.3) \\\\\n",
      "\\hline\n",
      "claude-3.5 & 86.9 (83.3--90.0) & -- & \\bf 87.1 (83.9--90.2) & 76.4 (72.9--79.9) & 82.9 (78.9--86.9) \\\\\n",
      "\\hline\n",
      "o3-mini & 72.8 (68.4--77.3) & -- & 74.7 (70.3--79.2) & 86.1 (83.9--88.4) & \\bf 92.4 (91.3--93.5) \\\\\n",
      "\\hline\n",
      "gpt-5 & 83.6 (79.1--87.7) & 85.0 (76.7--93.0) & -- & -- & \\bf 96.3 (94.6--98.3) \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_prompt_table_of_results(multi_prompts(results_t), multi_prompts(results_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4497f3",
   "metadata": {},
   "source": [
    "### Commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d492467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "produce_table(\n",
    "    {k: v for k, v in results_sc.items() if k in model_by_display_key},\n",
    "    [display_prompt_sc(p) for p in [\"Basic\", \"Basic-Commas\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4), dpi=400, facecolor=\"white\", tight_layout=True)\n",
    "plot_transducer_vs_sequence_completion(results_sc, results_t)\n",
    "plt.savefig(\"../output/sequence_completion_vs_transducer.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a6c93",
   "metadata": {},
   "source": [
    "### Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c440d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(r\"{\\scriptsize\")\n",
    "multi_prompt_table_of_results(\n",
    "    multi_prompts(null_t, minimum_number_prompts=1),\n",
    "    multi_prompts(null_sc, minimum_number_prompts=1),\n",
    "    bold_best=False,\n",
    ")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c732a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evallm.experiments.main_tables import flat_pandas_table, reorderings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca54843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def flat(result):\n",
    "    return {(k1, k2): np.mean(v) for k1, k2v in result.items() for k2, v in k2v.items()}\n",
    "\n",
    "\n",
    "for k, v in flat(null_sc).items():\n",
    "    if v < 0.05:\n",
    "        continue\n",
    "    if \"Commas\" in k[1]:\n",
    "        continue\n",
    "    print(k, v)\n",
    "    # print(k, np.mean(v))\n",
    "\n",
    "all_vals = np.array(\n",
    "    [\n",
    "        np.mean(v)\n",
    "        for null in (null_t, null_sc)\n",
    "        for vs in null.values()\n",
    "        for prompt, v in vs.items()\n",
    "        if \"Commas\" not in prompt\n",
    "    ]\n",
    ")\n",
    "\n",
    "all_vals[all_vals < 0.5].max(), all_vals[all_vals >= 0.6].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_sc = flat_pandas_table(results_sc, null_sc)\n",
    "table_t = flat_pandas_table(results_t, null_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642dbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sequence just same model\")\n",
    "reorderings(table_sc, same_model=True)\n",
    "print()\n",
    "print(\"Transducer just same model\")\n",
    "reorderings(table_t, same_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sequence just best prompt\")\n",
    "reorderings(table_sc, only_best_prompt=True)\n",
    "print()\n",
    "print(\"Transducer just best prompt\")\n",
    "reorderings(table_t, only_best_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_t = best_prompt(results_t)\n",
    "ps_t = all_p_values(flat_t)\n",
    "flat_sc = {\n",
    "    k: v\n",
    "    for k, v in best_prompt(results_sc).items()\n",
    "    if not isinstance(v, float) or not np.isnan(v)\n",
    "}\n",
    "ps_sc = all_p_values(flat_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 6\n",
    "_, axs = plt.subplots(1, 2, figsize=(size * 2, size), dpi=400, tight_layout=True)\n",
    "plot_significance(axs[0], flat_sc, ps_sc)\n",
    "axs[0].set_title(\"Sequence Completion\")\n",
    "plot_significance(axs[1], flat_t, ps_t)\n",
    "axs[1].set_title(\"Transducer\")\n",
    "plt.savefig(\"../output/significance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d429879-b8ba-4324-905c-894fd1d0d58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
