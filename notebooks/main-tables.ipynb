{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15afe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fe887b-d30f-4c00-acef-3c7a4902ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evallm.experiments.sequence_completion_summary import (\n",
    "    sequence_completion_results,\n",
    "    display_prompt as display_prompt_sc,\n",
    ")\n",
    "\n",
    "from evallm.experiments.transducer_summary import (\n",
    "    transducer_results,\n",
    ")\n",
    "from evallm.experiments.main_tables import (\n",
    "    best_prompt,\n",
    "    multi_prompts,\n",
    "    main_table_of_results,\n",
    "    multi_prompt_table_of_results,\n",
    ")\n",
    "\n",
    "from evallm.experiments.transducer_plotting import produce_table\n",
    "from evallm.experiments.models_display import model_by_display_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fefa73b-b8bb-4a39-ac8c-45f05c3b1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_t = transducer_results()\n",
    "results_sc = sequence_completion_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9151dd5a-d273-4fca-b9d4-28b16f0139c0",
   "metadata": {},
   "source": [
    "### Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255a0221-2c87-4268-868f-c8ed935de6bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|l|c|c|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "\\bf Model & \\bf Size & \\bf IT? & \\bf Code? & \\bf Sequence Completion & \\bf SR & \\bf Transducer & \\bf TR\\\\\n",
      "\\hline\n",
      "\\multicolumn{8}{|c|}{ \\bf Baselines} \\\\\n",
      "\\hline\n",
      "\\textsc{BruteForce} & -- &  &  & \\cellcolor{lightgray} 100.0 (99.9--100.0) & 1 & \\cellcolor{lightgray} 96.4 (96.2--96.7) & 1 \\\\\n",
      "\\hline\n",
      "6-\\textsc{Gram} & -- &  &  & \\bf 91.7 (91.0--92.4) & 2 & \\bf 93.5 (93.1--93.9) & 2 \\\\\n",
      "\\hline\n",
      "5-\\textsc{Gram} & -- &  &  & 91.2 (90.4--91.9) & 3 & 93.4 (93.0--93.7) & 3 \\\\\n",
      "\\hline\n",
      "4-\\textsc{Gram} & -- &  &  & 89.6 (88.7--90.4) & 4 & 91.1 (90.6--91.6) & 4 \\\\\n",
      "\\hline\n",
      "3-\\textsc{Gram} & -- &  &  & 87.0 (86.1--87.8) & 5 & 87.0 (86.4--87.6) & 16 \\\\\n",
      "\\hline\n",
      "2-\\textsc{Gram} & -- &  &  & 83.3 (82.2--84.2) & 8 & 74.5 (73.6--75.3) & 24 \\\\\n",
      "\\hline\n",
      "\\textsc{Common-Suffix} & -- &  &  & 84.7 (83.6--85.6) & 6 & -- & -- \\\\\n",
      "\\hline\n",
      "\\textsc{Null} & -- &  &  & -- & -- & 68.9 (68.2--69.6) & 25 \\\\\n",
      "\\hline\n",
      "\\textsc{Random} & -- &  &  & 53.3 (51.7--54.7) & 26 & -- & -- \\\\\n",
      "\\hline\n",
      "\\hline\n",
      "\\multicolumn{8}{|c|}{ \\bf Open Source Completion} \\\\\n",
      "\\hline\n",
      "llama3-8B & 8.0B &  &  & 73.8 (72.4--75.1) & 18 & 87.5 (86.9--88.0) & 14 \\\\\n",
      "\\hline\n",
      "llama3-70B & 70.6B &  &  & 71.4 (70.0--72.7) & 23 & 87.7 (87.2--88.3) & 12 \\\\\n",
      "\\hline\n",
      "llama3.1-8B-Instruct & 8.0B & \\checkmark &  & 75.3 (74.0--76.6) & 16 & 85.9 (85.3--86.5) & 18 \\\\\n",
      "\\hline\n",
      "mistral-nemo-minitron-8B & 8.4B &  &  & \\bf 78.7 (77.5--79.8) & 12 & \\bf 88.6 (88.0--89.1) & 5 \\\\\n",
      "\\hline\n",
      "mistral-nemo-base-12B & 12.2B &  &  & 75.5 (74.3--76.6) & 15 & 87.9 (87.4--88.4) & 10 \\\\\n",
      "\\hline\n",
      "mistral-nemo-instruct-12B & 12.2B & \\checkmark &  & 72.2 (70.9--73.4) & 22 & 88.0 (87.5--88.5) & 8 \\\\\n",
      "\\hline\n",
      "gemma-7b & 8.5B &  &  & 72.6 (71.3--73.7) & 20 & 82.1 (81.4--82.7) & 22 \\\\\n",
      "\\hline\n",
      "falcon-7b & 7.2B &  &  & 69.0 (67.6--70.2) & 24 & 84.9 (84.3--85.5) & 20 \\\\\n",
      "\\hline\n",
      "\\hline\n",
      "\\multicolumn{8}{|c|}{ \\bf Open Source Code} \\\\\n",
      "\\hline\n",
      "starcoder2-15b & 16.0B &  & \\checkmark & 73.5 (72.0--74.7) & 19 & 87.7 (85.8--89.5) & 13 \\\\\n",
      "\\hline\n",
      "codestral-22B & 22.2B &  & \\checkmark & 78.0 (76.8--79.1) & 13 & 86.6 (86.0--87.1) & 17 \\\\\n",
      "\\hline\n",
      "deepseek-coder-33b-instruct & 33.3B & \\checkmark & \\checkmark & 76.7 (75.3--77.8) & 14 & 85.6 (85.0--86.2) & 19 \\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-7B & 7.6B &  & \\checkmark & \\bf 79.5 (78.4--80.5) & 9 & 88.2 (87.6--88.7) & 7 \\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-7B & 7.6B & \\checkmark & \\checkmark & 79.5 (78.3--80.5) & 10 & \\bf 88.3 (87.8--88.8) & 6 \\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-32B & 32.8B & \\checkmark & \\checkmark & 79.2 (78.0--80.3) & 11 & 87.9 (87.4--88.4) & 9 \\\\\n",
      "\\hline\n",
      "\\hline\n",
      "\\multicolumn{8}{|c|}{ \\bf Proprietary} \\\\\n",
      "\\hline\n",
      "gpt-3.5-instruct & ? & \\checkmark &  & 67.3 (63.1--71.5) & 25 & \\bf 87.8 (85.9--89.6) & 11 \\\\\n",
      "\\hline\n",
      "gpt-3.5-chat & ? & \\checkmark &  & N/A & -- & 66.8 (63.4--69.8) & 26 \\\\\n",
      "\\hline\n",
      "gpt-4o-mini & ? & \\checkmark &  & 72.4 (68.1--76.3) & 21 & 79.8 (77.3--82.2) & 23 \\\\\n",
      "\\hline\n",
      "gpt-4o & ? & \\checkmark &  & 74.4 (69.9--78.6) & 17 & 83.7 (80.1--86.9) & 21 \\\\\n",
      "\\hline\n",
      "claude-3.5 & ? & \\checkmark &  & \\bf 84.0 (79.3--88.4) & 7 & 87.1 (83.9--90.2) & 15 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_table_of_results(best_prompt(results_t), best_prompt(results_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6818297b-d66f-429b-8628-974d4c21c63f",
   "metadata": {},
   "source": [
    "### Comparison of Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08243d8c-0466-4a7c-9d9d-4f9d4b6b97e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|l|c|c|c|c|}\n",
      "\\hline\n",
      "\\bf Model & \\bf \\textsc{Basic} & \\bf \\textsc{More-Expl} & \\bf \\textsc{COT} & \\bf \\textsc{Red-Green} \\\\\n",
      "\\hline\n",
      "\\hline\n",
      "\\multicolumn{5}{|l|}{ \\bf Sequence Completion} \\\\\n",
      "\\hline\n",
      "gpt-4o-mini & \\bf 72.4 (68.1--76.3) & 70.5 (66.4--74.6) & 58.0 (53.4--62.4) & 59.1 (54.9--63.2) \\\\\n",
      "\\hline\n",
      "gpt-4o & 72.1 (65.9--78.2) & N/A & 67.4 (60.8--73.8) & \\bf 74.4 (69.9--78.6) \\\\\n",
      "\\hline\n",
      "claude-3.5 & N/A & N/A & \\bf 84.0 (79.3--88.4) & 80.0 (74.9--85.2) \\\\\n",
      "\\hline\n",
      "\\hline\n",
      "\\multicolumn{5}{|l|}{ \\bf Transducer} \\\\\n",
      "\\hline\n",
      "gpt-4o-mini & \\bf 79.8 (77.3--82.2) & 76.7 (74.2--79.3) & 65.2 (63.1--67.4) & 74.5 (72.0--77.0) \\\\\n",
      "\\hline\n",
      "gpt-4o & \\bf 83.7 (80.1--86.9) & 82.6 (79.1--85.9) & 67.8 (63.1--72.3) & 82.6 (78.8--86.3) \\\\\n",
      "\\hline\n",
      "claude-3.5 & 86.9 (83.3--90.0) & \\bf 87.1 (83.9--90.2) & 76.4 (72.9--79.9) & 82.9 (78.9--86.9) \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_prompt_table_of_results(multi_prompts(results_t), multi_prompts(results_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130297e-0c36-49ad-a233-f6d3a16ab3fc",
   "metadata": {},
   "source": [
    "### Commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a7bef5-2314-4760-9e7f-f3d8ae7cf610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|r|c|c|}\n",
      "\\hline\n",
      "Model & \\textsc{Basic}$_S$ & \\textsc{Basic-Commas}$_S$\\\\\n",
      "\\hline\n",
      "\\bf qwen-2.5-coder-7B &\\bf 79.5 (78.4--80.5)&\\bf 60.7 (59.3--62.1)\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-7B &79.5 (78.3--80.5)&55.5 (54.0--56.9)\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-32B &79.2 (78.0--80.3)&55.2 (53.7--56.7)\\\\\n",
      "\\hline\n",
      "mistral-nemo-minitron-8B &78.7 (77.5--79.8)&59.3 (57.9--60.8)\\\\\n",
      "\\hline\n",
      "codestral-22B &78.0 (76.8--79.1)&59.0 (57.5--60.3)\\\\\n",
      "\\hline\n",
      "deepseek-coder-33b-instruct &76.7 (75.3--77.8)&54.9 (53.0--56.8)\\\\\n",
      "\\hline\n",
      "mistral-nemo-base-12B &75.5 (74.3--76.6)&60.6 (59.1--62.2)\\\\\n",
      "\\hline\n",
      "llama3.1-8B-Instruct &75.3 (74.0--76.6)&56.3 (54.4--58.1)\\\\\n",
      "\\hline\n",
      "llama3-8B &73.8 (72.4--75.1)&61.5 (60.2--62.9)\\\\\n",
      "\\hline\n",
      "starcoder2-15b &73.5 (72.0--74.7)&58.2 (56.7--59.8)\\\\\n",
      "\\hline\n",
      "gemma-7b &72.6 (71.3--73.7)&54.0 (51.9--56.0)\\\\\n",
      "\\hline\n",
      "gpt-4o-mini &72.4 (68.1--76.3)&64.1 (59.5--68.3)\\\\\n",
      "\\hline\n",
      "mistral-nemo-instruct-12B &72.2 (70.9--73.4)&58.2 (56.4--59.8)\\\\\n",
      "\\hline\n",
      "gpt-4o &72.1 (65.9--78.2)&66.8 (58.5--74.8)\\\\\n",
      "\\hline\n",
      "llama3-70B &71.4 (70.0--72.7)&56.4 (54.7--58.0)\\\\\n",
      "\\hline\n",
      "falcon-7b &69.0 (67.6--70.2)&56.1 (54.5--57.6)\\\\\n",
      "\\hline\n",
      "gpt-3.5-instruct &67.3 (63.1--71.5)&52.3 (46.5--57.9)\\\\\n",
      "\\hline\n",
      "claude-3.5 &N/A&N/A\\\\\n",
      "\\hline\n",
      "gpt-3.5-chat &N/A&N/A\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "produce_table(\n",
    "    {k: v for k, v in results_sc.items() if k in model_by_display_key},\n",
    "    [display_prompt_sc(p) for p in [\"Basic\", \"Basic-Commas\"]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
