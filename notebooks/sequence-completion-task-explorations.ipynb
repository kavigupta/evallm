{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15afe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fe887b-d30f-4c00-acef-3c7a4902ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evallm\n",
    "from evallm.experiments.transducer_experiment import (\n",
    "    current_dfa_sample_spec,\n",
    ")\n",
    "\n",
    "from evallm.experiments.models_display import model_by_display_key\n",
    "\n",
    "from evallm.experiments.transducer_plotting import produce_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88e1a29-dde6-4508-9d0f-b179814a010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evallm.experiments.sequence_completion.sequence_completion_prompt import (\n",
    "    SequencePromptDirectAlien,\n",
    "    SequencePromptDirectAlienWithSpaces,\n",
    "    SequencePromptDirectAlien2,\n",
    "    SequencePromptDirectAlien3,\n",
    "    SequencePromptDirectAlien2WithSpaces,\n",
    "    SequencePromptDirectAlien2WithCommas,\n",
    "    SequencePromptDirectAlien3WithSpaces,\n",
    "    SequencePromptDirectAlien2WithCommasSequence,\n",
    "    MoreExplanationPrompt,\n",
    "    MoreExplanationPrompt2,\n",
    "    RedGreenPrompt,\n",
    "    MoreExplanationPromptCOT,\n",
    ")\n",
    "\n",
    "from evallm.experiments.sequence_completion.sequence_completion_experiments import (\n",
    "    compute_model_scores,\n",
    "    compute_ngram_scores,\n",
    "    compute_ngram_scores_with_prefix,\n",
    "    compute_random_baseline_scores,\n",
    "    compute_brute_force_scores,\n",
    "    get_examples,\n",
    "    run_model,\n",
    "    compute_true_ngrams,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d109dfca-99d4-4c22-83d0-e854f460fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = current_dfa_sample_spec(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90fc9d9d-b8c1-40d4-89e1-d0993d3c348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequence_symbols = 10\n",
    "current_setting = dict(\n",
    "    dfa_spec=spec,\n",
    "    num_sequences=30,\n",
    "    num_sequence_symbols=num_sequence_symbols,\n",
    "    num_sequence_symbols_prompt=num_sequence_symbols // 2,\n",
    "    num_instances=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c546616-1c62-4ab9-bfde-628b853d5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = get_examples(0, current_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592c0ed4-6091-4e68-bb35-9044624831e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_by_key = {\n",
    "    \"Basic\": SequencePromptDirectAlien2.for_setting,\n",
    "    \"Basic-Commas\": SequencePromptDirectAlien2WithCommas.for_setting,\n",
    "    \"More-Expl\": MoreExplanationPrompt2.for_setting,\n",
    "    \"COT\": MoreExplanationPromptCOT.for_setting,\n",
    "    \"Red-Green\": RedGreenPrompt.for_setting,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2710d0bd-b9b0-4d05-adb5-dc4a37452975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_model(model, count, *prompts):\n",
    "    return {\n",
    "        (model, prompt): compute_model_scores(\n",
    "            count,\n",
    "            current_setting,\n",
    "            model_by_display_key[model],\n",
    "            prompts_by_key[prompt],\n",
    "            na_mode=\"ignore\",\n",
    "        )\n",
    "        for prompt in prompts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276e5d67-30a5-420f-94b3-482b19506305",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    # **for_model(\"mistral-nemo-minitron-8B\", 1000, \"Basic\"),\n",
    "    **for_model(\"llama3-8B\", 1000, \"Basic\", \"Basic-Commas\"),\n",
    "    **for_model(\"llama3-70B\", 1000, \"Basic\"),\n",
    "    **for_model(\"qwen-2.5-coder-instruct-7B\", 1000, \"Basic\"),\n",
    "    **for_model(\"qwen-2.5-coder-instruct-32B\", 1000, \"Basic\", \"Basic-Commas\"),\n",
    "    **for_model(\"qwen-2.5-coder-7B\", 1000, \"Basic\", \"Basic-Commas\"),\n",
    "    # **for_model(\"llama3.1-8B-Instruct\", 1000, \"Basic\"),\n",
    "    **for_model(\"mistral-nemo-minitron-8B\", 1000, \"Basic\"),\n",
    "    # **for_model(\"mistral-nemo-base-12B\", 1000, \"Basic\"),\n",
    "    # **for_model(\"mistral-nemo-instruct-12B\", 1000, \"Basic\"),\n",
    "    # **for_model(\"gemma-7b\", 1000, \"Basic\"),\n",
    "    # **for_model(\"falcon-7b\", 1000, \"Basic\"),\n",
    "    **for_model(\"gpt-3.5-instruct\", 100, \"Basic\", \"Basic-Commas\"),\n",
    "    **for_model(\"gpt-3.5-chat\", 100, \"Basic\", \"Basic-Commas\"),\n",
    "    **for_model(\n",
    "        \"gpt-4o-mini\", 100, \"Basic\", \"Basic-Commas\", \"More-Expl\", \"COT\", \"Red-Green\"\n",
    "    ),\n",
    "    **for_model(\"gpt-4o\", 30, \"Basic\", \"Basic-Commas\", \"More-Expl\"),\n",
    "    **for_model(\"gpt-4o\", 30, \"COT\", \"Red-Green\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91904ce-02cb-4f0c-a52c-64b5cd053041",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_baselines = 100\n",
    "\n",
    "results[r\"\\textsc{Random}\", \"Basic\"] = compute_random_baseline_scores(\n",
    "    amount_baselines, setting=current_setting\n",
    ")\n",
    "\n",
    "results[r\"\\textsc{Common-Suffix}\", \"Basic\"] = compute_ngram_scores(\n",
    "    amount_baselines, setting=current_setting\n",
    ")\n",
    "\n",
    "results[r\"$\\textsc{BruteForce}_S$\", \"Basic\"] = compute_brute_force_scores(\n",
    "    44, current_setting\n",
    ")\n",
    "\n",
    "for ngram in (2, 3, 4, 5, 6):\n",
    "    results[rf\"{ngram}-$\\textsc{{Gram}}_S$\", \"Basic\"] = compute_true_ngrams(\n",
    "        ngram, amount_baselines, current_setting\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce54f9c8-89b4-4f50-adb0-1d34a6791243",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nested = {m: {} for m, _ in results}\n",
    "for m, p in results:\n",
    "    results_nested[m][p] = results[m, p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d8500b8-7569-4592-8573-dd7bd3c96029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|r|c|c|c|c|c|}\n",
      "\\hline\n",
      "Model & \\textsc{Basic} & \\textsc{Basic-Commas} & \\textsc{More-Expl} & \\textsc{COT} & \\textsc{Red-Green}\\\\\n",
      "\\hline\n",
      "\\cellcolor{lightgray}$\\textsc{BruteForce}_S$ &\\cellcolor{lightgray}100.0 (100.0--100.0)&--&--&--&--\\\\\n",
      "\\hline\n",
      "\\bf 6-$\\textsc{Gram}_S$ &\\bf 91.9 (89.3--94.0)&--&--&--&--\\\\\n",
      "\\hline\n",
      "5-$\\textsc{Gram}_S$ &91.4 (88.8--93.7)&--&--&--&--\\\\\n",
      "\\hline\n",
      "4-$\\textsc{Gram}_S$ &90.5 (87.8--92.9)&--&--&--&--\\\\\n",
      "\\hline\n",
      "3-$\\textsc{Gram}_S$ &86.3 (83.2--88.8)&--&--&--&--\\\\\n",
      "\\hline\n",
      "\\textsc{Common-Suffix} &83.4 (79.8--86.8)&--&--&--&--\\\\\n",
      "\\hline\n",
      "2-$\\textsc{Gram}_S$ &82.3 (78.8--85.4)&--&--&--&--\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-7B &79.5 (78.4--80.5)&60.7 (59.3--62.1)&--&--&--\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-7B &79.5 (78.3--80.5)&--&--&--&--\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-32B &79.2 (78.0--80.3)&55.2 (53.7--56.7)&--&--&--\\\\\n",
      "\\hline\n",
      "mistral-nemo-minitron-8B &78.7 (77.5--79.8)&--&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-4o &72.1 (65.9--78.2)&66.8 (58.5--74.8)&invalid&67.4 (60.8--73.8)&74.4 (69.9--78.6)\\\\\n",
      "\\hline\n",
      "llama3-8B &73.8 (72.4--75.1)&61.5 (60.2--62.9)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-4o-mini &72.4 (68.1--76.3)&64.1 (59.5--68.3)&70.5 (66.4--74.6)&58.0 (53.4--62.4)&59.1 (54.9--63.2)\\\\\n",
      "\\hline\n",
      "llama3-70B &71.4 (70.0--72.7)&--&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-3.5-instruct &67.3 (63.1--71.5)&52.3 (46.5--57.9)&--&--&--\\\\\n",
      "\\hline\n",
      "\\textsc{Random} &51.2 (46.6--55.8)&--&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-3.5-chat &invalid&invalid&--&--&--\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "produce_table(results_nested, list(prompts_by_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa0c535-f0ba-4693-a669-cd8ca11e4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompter = prompts_by_key[\"Basic-Commas\"](current_setting)\n",
    "# responses = run_model(model_by_display_key[\"qwen-2.5-coder-7B\"], prompter, *example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a165f948-baf1-4591-af61-0f238363bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prompter.display_prompt(None, *example[1][0], is_chat=True)[\"user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95bbaabd-9bf6-4338-bcb1-efc57030fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b888ef3-bab0-476a-8f50-790b5a7d0abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
