{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15afe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625808e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import evallm\n",
    "from automata.fa.dfa import DFA\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294c9a50-c317-4a8a-9396-afa17e1e26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from permacache import stable_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fe887b-d30f-4c00-acef-3c7a4902ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evallm.experiments.transducer_plotting import produce_table\n",
    "\n",
    "from evallm.experiments.transducer_summary import compute_results, prompt_by_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373f5e4b-31cd-41f2-820a-1d840b459c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f7f83b-f9ae-47ed-afe4-bf108f33ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = list(prompt_by_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d9e06a-3912-48be-af90-91682baefbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prompt(p):\n",
    "    return rf\"\\textsc{{{p}}}$_T$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36326e6c-108f-42dc-86c2-a88ea38883f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|r|c|c|c|c|}\n",
      "\\hline\n",
      "Model & \\textsc{Basic}$_T$ & \\textsc{More-Expl}$_T$ & \\textsc{COT}$_T$ & \\textsc{Red-Green}$_T$\\\\\n",
      "\\hline\n",
      "\\cellcolor{lightgray}\\textsc{BruteForce}$_T$ &\\cellcolor{lightgray}96.4 (96.2--96.7)&--&--&--\\\\\n",
      "\\hline\n",
      "\\bf 6-\\textsc{Gram}$_T$ &\\bf 93.5 (93.1--93.9)&--&--&--\\\\\n",
      "\\hline\n",
      "5-\\textsc{Gram}$_T$ &93.4 (93.0--93.7)&--&--&--\\\\\n",
      "\\hline\n",
      "4-\\textsc{Gram}$_T$ &91.1 (90.6--91.6)&--&--&--\\\\\n",
      "\\hline\n",
      "mistral-nemo-minitron-8B &88.6 (88.0--89.1)&--&--&--\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-7B &88.3 (87.8--88.8)&--&--&--\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-7B &88.2 (87.6--88.7)&--&--&--\\\\\n",
      "\\hline\n",
      "mistral-nemo-instruct-12B &88.0 (87.5--88.5)&--&--&--\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-32B &87.9 (87.4--88.4)&--&--&--\\\\\n",
      "\\hline\n",
      "mistral-nemo-base-12B &87.9 (87.4--88.4)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-3.5-instruct &87.8 (85.9--89.6)&--&--&--\\\\\n",
      "\\hline\n",
      "llama3-70B &87.7 (87.2--88.3)&--&--&--\\\\\n",
      "\\hline\n",
      "starcoder2-15b &87.7 (85.8--89.5)&--&--&--\\\\\n",
      "\\hline\n",
      "llama3-8B &87.5 (86.9--88.0)&--&--&--\\\\\n",
      "\\hline\n",
      "claude-3.5 &86.9 (83.3--90.0)&87.1 (83.9--90.2)&76.4 (72.9--79.9)&82.9 (78.9--86.9)\\\\\n",
      "\\hline\n",
      "3-\\textsc{Gram}$_T$ &87.0 (86.4--87.6)&--&--&--\\\\\n",
      "\\hline\n",
      "codestral-22B &86.6 (86.0--87.1)&--&--&--\\\\\n",
      "\\hline\n",
      "llama3.1-8B-Instruct &85.9 (85.3--86.5)&--&--&--\\\\\n",
      "\\hline\n",
      "deepseek-coder-33b-instruct &85.6 (85.0--86.2)&--&--&--\\\\\n",
      "\\hline\n",
      "falcon-7b &84.9 (84.3--85.5)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-4o &83.7 (80.1--86.9)&82.6 (79.1--85.9)&67.8 (63.1--72.3)&82.6 (78.8--86.3)\\\\\n",
      "\\hline\n",
      "gemma-7b &82.1 (81.4--82.7)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-4o-mini &79.8 (77.3--82.2)&76.7 (74.2--79.3)&65.2 (63.1--67.4)&74.5 (72.0--77.0)\\\\\n",
      "\\hline\n",
      "2-\\textsc{Gram}$_T$ &74.5 (73.6--75.3)&--&--&--\\\\\n",
      "\\hline\n",
      "\\textsc{Null}$_T$ &68.9 (68.2--69.6)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-3.5-chat &66.8 (63.4--69.8)&--&--&--\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "produce_table(\n",
    "    {\n",
    "        m: {display_prompt(p): accuracies[m][p] for p in accuracies[m]}\n",
    "        for m in accuracies\n",
    "    },\n",
    "    [display_prompt(p) for p in prompt_by_key],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eedcf6-a0c7-40b2-bf81-838ad02f9d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
