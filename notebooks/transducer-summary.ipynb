{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15afe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625808e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import evallm\n",
    "from automata.fa.dfa import DFA\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294c9a50-c317-4a8a-9396-afa17e1e26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from permacache import stable_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fe887b-d30f-4c00-acef-3c7a4902ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evallm.llm.llm import model_specs\n",
    "from evallm.prompting.transducer_prompt import (\n",
    "    BasicSequencePrompt,\n",
    "    BasicSequencePromptSlightlyMoreExplanation,\n",
    "    BasicSequencePromptNoChat,\n",
    "    SequencePromptWithExplanation,\n",
    "    SequencePromptWithExplanationChainOfThought,\n",
    "    RedGreenRoomPrompt1,\n",
    "    BasicInstructionTransducerPrompter,\n",
    ")\n",
    "from evallm.experiments.transducer_experiment import (\n",
    "    current_transducer_experiments,\n",
    "    compute_relative_to_null,\n",
    "    compute_relative_to_ngram,\n",
    "    print_example,\n",
    "    bottom_quartile_outcome,\n",
    "    current_dfa_sample_spec,\n",
    "    run_transducer_experiment_just_stats,\n",
    "    run_transducer_experiment,\n",
    "    run_brute_force_transducer,\n",
    ")\n",
    "from evallm.experiments.transducer_plotting import (\n",
    "    plot_all_absolute_results_single_graph,\n",
    "    plot_absolute_results_barchart,\n",
    "    produce_table,\n",
    ")\n",
    "from evallm.experiments.models_display import model_by_display_key\n",
    "from evallm.utils.bootstrap import boostrap_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373f5e4b-31cd-41f2-820a-1d840b459c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 3\n",
    "num_symbols = 3\n",
    "num_sequence_symbols = 30\n",
    "num_repeats_per_dfa = 30\n",
    "sample_dfa_spec = current_dfa_sample_spec(num_states=num_states)\n",
    "setting_kwargs = dict(\n",
    "    num_sequence_symbols=num_sequence_symbols,\n",
    "    sample_dfa_spec=sample_dfa_spec,\n",
    "    num_states=num_states,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8facd648-8323-414f-8965-7b2598aaac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_by_key = {\n",
    "    \"Basic\": {\n",
    "        \"non-chat\": BasicSequencePromptNoChat.for_setting(setting_kwargs),\n",
    "        \"chat\": BasicSequencePrompt.for_setting(setting_kwargs),\n",
    "    },\n",
    "    \"More-Expl\": {\n",
    "        \"chat\": BasicSequencePromptSlightlyMoreExplanation.for_setting(setting_kwargs)\n",
    "    },\n",
    "    \"COT\": {\n",
    "        \"chat\": SequencePromptWithExplanationChainOfThought.for_setting(setting_kwargs)\n",
    "    },\n",
    "    \"Red-Green\": {\"chat\": RedGreenRoomPrompt1.for_setting(setting_kwargs)},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce74b2a-43e1-4097-8792-6635dc780c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_model_and_prompt(model, num_dfas, *prompts):\n",
    "    model_key = model_by_display_key[model]\n",
    "    if model_specs[model_key].is_chat:\n",
    "        prompt_kind = \"chat\"\n",
    "    else:\n",
    "        prompt_kind = \"non-chat\"\n",
    "    return {\n",
    "        (model, prompt): run_transducer_experiment(\n",
    "            model_key,\n",
    "            sample_dfa_spec,\n",
    "            prompt_by_key[prompt][prompt_kind],\n",
    "            num_repeats_per_dfa=num_repeats_per_dfa,\n",
    "            num_dfas=num_dfas,\n",
    "        )\n",
    "        for prompt in prompts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c759712b-8543-46cb-a443-11a1a4b0abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic_baseline_outcomes = run_transducer_experiment_just_stats(\n",
    "    \"none\",\n",
    "    sample_dfa_spec,\n",
    "    BasicInstructionTransducerPrompter(num_sequence_symbols, strip=True),\n",
    "    num_repeats_per_dfa=num_repeats_per_dfa,\n",
    "    num_dfas=1000,\n",
    ")\n",
    "model_outcomes = {\n",
    "    **for_model_and_prompt(\"llama3-8B\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"llama3-70B\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"llama3.1-8B-Instruct\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"starcoder2-15b\", 100, \"Basic\"),\n",
    "    **for_model_and_prompt(\"codestral-22B\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"deepseek-coder-33b-instruct\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"qwen-2.5-coder-7B\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"qwen-2.5-coder-instruct-7B\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"mistral-nemo-minitron-8B\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"mistral-nemo-base-12B\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"mistral-nemo-instruct-12B\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"gemma-7b\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"falcon-7b\", 1000, \"Basic\"),\n",
    "    **for_model_and_prompt(\"gpt-3.5-instruct\", 100, \"Basic\"),\n",
    "    **for_model_and_prompt(\"gpt-3.5-chat\", 100, \"Basic\"),\n",
    "    **for_model_and_prompt(\n",
    "        \"gpt-4o-mini\",\n",
    "        100,\n",
    "        \"Basic\",\n",
    "        \"More-Expl\",\n",
    "        \"COT\",\n",
    "        \"Red-Green\",\n",
    "    ),\n",
    "    **for_model_and_prompt(\"gpt-4o\", 30, \"Basic\"),\n",
    "    **for_model_and_prompt(\n",
    "        \"claude-3.5\",\n",
    "        30,\n",
    "        \"Basic\",\n",
    "        \"More-Expl\",\n",
    "        \"COT\",\n",
    "        \"Red-Green\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23b3e7f-3e11-497b-992f-9aaafc055a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_prompt = \"Basic\"\n",
    "\n",
    "accuracies = defaultdict(dict)\n",
    "accuracies[r\"\\textsc{Null}$_T$\"][no_prompt] = [\n",
    "    r.null_success_rate for r in deterministic_baseline_outcomes\n",
    "]\n",
    "for ngram in range(2, 2 + 5):\n",
    "    accuracies[rf\"{ngram}-\\textsc{{Gram}}$_T$\"][no_prompt] = [\n",
    "        r.kgram_success_rates_each[ngram - 2] for r in deterministic_baseline_outcomes\n",
    "    ]\n",
    "accuracies[r\"\\textsc{BruteForce}$_T$\"][no_prompt] = run_brute_force_transducer(\n",
    "    sample_dfa_spec,\n",
    "    num_states,\n",
    "    num_symbols,\n",
    "    num_sequence_symbols,\n",
    "    num_repeats_per_dfa,\n",
    "    num_dfas=1000,\n",
    ")\n",
    "for model, prompt in model_outcomes:\n",
    "    accuracies[model][prompt] = [\n",
    "        r.success_rate_binary_ignore_na for r in model_outcomes[model, prompt]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f7f83b-f9ae-47ed-afe4-bf108f33ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = list(prompt_by_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d9e06a-3912-48be-af90-91682baefbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prompt(p):\n",
    "    return rf\"\\textsc{{{p}}}$_T$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36326e6c-108f-42dc-86c2-a88ea38883f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|r|c|c|c|c|}\n",
      "\\hline\n",
      "Model & \\textsc{Basic}$_T$ & \\textsc{More-Expl}$_T$ & \\textsc{COT}$_T$ & \\textsc{Red-Green}$_T$\\\\\n",
      "\\hline\n",
      "\\cellcolor{lightgray}\\textsc{BruteForce}$_T$ &\\cellcolor{lightgray}96.4 (96.2--96.7)&--&--&--\\\\\n",
      "\\hline\n",
      "\\bf 6-\\textsc{Gram}$_T$ &\\bf 93.5 (93.1--93.9)&--&--&--\\\\\n",
      "\\hline\n",
      "5-\\textsc{Gram}$_T$ &93.4 (93.0--93.7)&--&--&--\\\\\n",
      "\\hline\n",
      "4-\\textsc{Gram}$_T$ &91.1 (90.6--91.6)&--&--&--\\\\\n",
      "\\hline\n",
      "mistral-nemo-minitron-8B &88.6 (88.0--89.1)&--&--&--\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-instruct-7B &88.3 (87.8--88.8)&--&--&--\\\\\n",
      "\\hline\n",
      "qwen-2.5-coder-7B &88.2 (87.6--88.7)&--&--&--\\\\\n",
      "\\hline\n",
      "mistral-nemo-instruct-12B &88.0 (87.5--88.5)&--&--&--\\\\\n",
      "\\hline\n",
      "mistral-nemo-base-12B &87.9 (87.4--88.4)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-3.5-instruct &87.8 (85.9--89.6)&--&--&--\\\\\n",
      "\\hline\n",
      "llama3-70B &87.7 (87.2--88.3)&--&--&--\\\\\n",
      "\\hline\n",
      "starcoder2-15b &87.7 (85.8--89.5)&--&--&--\\\\\n",
      "\\hline\n",
      "llama3-8B &87.5 (86.9--88.0)&--&--&--\\\\\n",
      "\\hline\n",
      "claude-3.5 &86.9 (83.3--90.0)&87.1 (83.9--90.2)&76.4 (72.9--79.9)&82.9 (78.9--86.9)\\\\\n",
      "\\hline\n",
      "3-\\textsc{Gram}$_T$ &87.0 (86.4--87.6)&--&--&--\\\\\n",
      "\\hline\n",
      "codestral-22B &86.6 (86.0--87.1)&--&--&--\\\\\n",
      "\\hline\n",
      "llama3.1-8B-Instruct &85.9 (85.3--86.5)&--&--&--\\\\\n",
      "\\hline\n",
      "deepseek-coder-33b-instruct &85.6 (85.0--86.2)&--&--&--\\\\\n",
      "\\hline\n",
      "falcon-7b &84.9 (84.3--85.5)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-4o &83.7 (80.1--86.9)&--&--&--\\\\\n",
      "\\hline\n",
      "gemma-7b &82.1 (81.4--82.7)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-4o-mini &79.8 (77.3--82.2)&76.7 (74.2--79.3)&65.2 (63.1--67.4)&74.5 (72.0--77.0)\\\\\n",
      "\\hline\n",
      "2-\\textsc{Gram}$_T$ &74.5 (73.6--75.3)&--&--&--\\\\\n",
      "\\hline\n",
      "\\textsc{Null}$_T$ &68.9 (68.2--69.6)&--&--&--\\\\\n",
      "\\hline\n",
      "gpt-3.5-chat &66.8 (63.4--69.8)&--&--&--\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "produce_table(\n",
    "    {\n",
    "        m: {display_prompt(p): accuracies[m][p] for p in accuracies[m]}\n",
    "        for m in accuracies\n",
    "    },\n",
    "    [display_prompt(p) for p in prompt_by_key],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eedcf6-a0c7-40b2-bf81-838ad02f9d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
